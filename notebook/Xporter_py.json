{
	"name": "Xporter_py",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p2sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "85647459-5583-404d-8d07-99d93ba6d6a4"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/79a9a1b8-17c9-4098-bbae-16c21b7edd2a/resourceGroups/rg-oea-cbuk07/providers/Microsoft.Synapse/workspaces/syn-oea-cbuk07/bigDataPools/spark3p2sm",
				"name": "spark3p2sm",
				"type": "Spark",
				"endpoint": "https://syn-oea-cbuk07.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p2sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import col\r\n",
					"\"\"\"\r\n",
					"Provides data processing methods for Community Brands Xporter data.\r\n",
					"Data is expected to be received via Xporter into oea/Transactional\r\n",
					"The structure of the folders in oea(Primary) will then be something like:\r\n",
					"    -> oea/transactional/xporter/[EstabId]\r\n",
					"        ->  oea/transactional/xporter/[EstabId]/Schoolinfo.json\r\n",
					"        -> oea/transactional/xporter/[EstabId]/Students.json\r\n",
					"        etc\r\n",
					"In stage1, everything is written to stage1/Transactional/xporter and stage2/[Ingested/refined]/xporter\r\n",
					"\"\"\"\r\n",
					"class Xporter():\r\n",
					"    def __init__(self, source_folder='xporter', pseudonymize = True):\r\n",
					"        self.set_oea_workspace('prod')\r\n",
					"        self.schemas = {}\r\n",
					"        self.schemas['schoolinfo'] = [\r\n",
					"                                        ['CurrentAcademicYear', 'string', 'no-op'],\r\n",
					"                                        ['DeniNo', 'string', 'no-op'],\r\n",
					"                                        ['Email', 'string', 'no-op'],\r\n",
					"                                        ['EstabId', 'string', 'no-op'],\r\n",
					"                                        ['ExamCentre', 'string', 'no-op'],\r\n",
					"                                        ['Governance', 'string', 'no-op'],\r\n",
					"                                        ['Head', 'string', 'no-op'],\r\n",
					"                                        ['Id', 'string', 'no-op'],\r\n",
					"                                        ['LastUpdated', 'string', 'no-op'],\r\n",
					"                                        ['MainContact', 'string', 'no-op'],\r\n",
					"                                        ['Name', 'string', 'no-op'],\r\n",
					"                                        ['Phase', 'string', 'no-op'],\r\n",
					"                                        ['RowHash', 'string', 'mask'],\r\n",
					"                                        ['SchoolLogoAlternateUrl', 'string', 'no-op'],\r\n",
					"                                        ['SchoolLogoUrl', 'string', 'no-op'],\r\n",
					"                                        ['Telephone', 'string', 'no-op'],\r\n",
					"                                        ['Web', 'string', 'no-op'],\r\n",
					"                                        ['SchoolKey', 'string', 'no-op'],\r\n",
					"                                        ['SchoolID', 'string', 'hash'],\r\n",
					"                                        ['Address', 'string', 'no-op']]\r\n",
					"\r\n",
					"        self.schemas['students'] = [    ['AdmissionNo', 'string', 'no-op'],\r\n",
					"                                        ['Apartment', 'string', 'no-op'],\r\n",
					"                                        ['AsylumStatus', 'string', 'no-op'],\r\n",
					"                                        ['AttMarksEndDate', 'string', 'no-op'],\r\n",
					"                                        ['AttMarksStartDate', 'string', 'no-op'],\r\n",
					"                                        ['Boarder', 'string', 'no-op'],\r\n",
					"                                        ['BoardingHouse', 'string', 'no-op'],\r\n",
					"                                        ['CandidateNo', 'string', 'no-op'],\r\n",
					"                                        ['Country', 'string', 'no-op'],\r\n",
					"                                        ['CountryOfBirth', 'string', 'no-op'],\r\n",
					"                                        ['CountryOfBirthCode', 'string', 'no-op'],\r\n",
					"                                        ['County', 'string', 'no-op'],\r\n",
					"                                        ['DateofBirth', 'string', 'mask'],\r\n",
					"                                        ['Destination', 'string', 'no-op'],\r\n",
					"                                        ['DestinationStartDate', 'string', 'no-op'],\r\n",
					"                                        ['Disabled', 'string', 'no-op'],\r\n",
					"                                        ['DisplayName', 'string', 'no-op'],\r\n",
					"                                        ['District', 'string', 'no-op'],\r\n",
					"                                        ['EAL', 'string', 'no-op'],\r\n",
					"                                        ['EnglishProficiencyLevel', 'string', 'no-op'],\r\n",
					"                                        ['EnglishProficiencyLevelCode', 'string', 'no-op'],\r\n",
					"                                        ['EnrolmentStatus', 'string', 'no-op'],\r\n",
					"                                        ['EntryDate', 'string', 'no-op'],\r\n",
					"                                        ['Ethnicity', 'string', 'no-op'],\r\n",
					"                                        ['EthnicityCode', 'string', 'no-op'],\r\n",
					"                                        ['EthnicitySource', 'string', 'no-op'],\r\n",
					"                                        ['EverInCare', 'string', 'no-op'],\r\n",
					"                                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                                        ['FSMEver6', 'string', 'no-op'],\r\n",
					"                                        ['FirstLanguage', 'string', 'no-op'],\r\n",
					"                                        ['FirstLanguageCode', 'string', 'no-op'],\r\n",
					"                                        ['FirstLanguageSource', 'string', 'no-op'],\r\n",
					"                                        ['Forename', 'string', 'no-op'],\r\n",
					"                                        ['FsmEligible', 'string', 'no-op'],\r\n",
					"                                        ['FsmStartDate', 'string', 'no-op'],\r\n",
					"                                        ['FsmEndDate', 'string', 'no-op'],\r\n",
					"                                        ['Gender', 'string', 'no-op'],\r\n",
					"                                        ['Gifted', 'string', 'no-op'],\r\n",
					"                                        ['HomeLanguage', 'string', 'no-op'],\r\n",
					"                                        ['HomeLanguageCode', 'string', 'no-op'],\r\n",
					"                                        ['HouseGroup', 'string', 'no-op'],\r\n",
					"                                        ['HouseGroupId', 'string', 'no-op'],\r\n",
					"                                        ['HouseName', 'string', 'no-op'],\r\n",
					"                                        ['HouseNo', 'string', 'no-op'],\r\n",
					"                                        ['Id', 'string', 'no-op'],\r\n",
					"                                        ['IdaasEmail', 'string', 'no-op'],\r\n",
					"                                        ['IdaasId', 'string', 'no-op'],\r\n",
					"                                        ['InLeaCare', 'string', 'no-op'],\r\n",
					"                                        ['IsTraveller', 'string', 'no-op'],\r\n",
					"                                        ['IsYoungCarer', 'string', 'no-op'],\r\n",
					"                                        ['KeyStage', 'string', 'no-op'],\r\n",
					"                                        ['LastUpdated', 'string', 'no-op'],\r\n",
					"                                        ['LeaCareAuthority', 'string', 'no-op'],\r\n",
					"                                        ['LeavingDate', 'string', 'no-op'],\r\n",
					"                                        ['LeavingRegGroup', 'string', 'no-op'],\r\n",
					"                                        ['LeavingYearGroup', 'string', 'no-op'],\r\n",
					"                                        ['LegalForename', 'string', 'no-op'],\r\n",
					"                                        ['LegalSurname', 'string', 'no-op'],\r\n",
					"                                        ['Marks', 'string', 'no-op'],\r\n",
					"                                        ['MiddleName', 'string', 'no-op'],\r\n",
					"                                        ['ModeOfTravel', 'string', 'no-op'],\r\n",
					"                                        ['NCYear', 'string', 'no-op'],\r\n",
					"                                        ['NationalIdentity', 'string', 'no-op'],\r\n",
					"                                        ['Nationality', 'string', 'no-op'],\r\n",
					"                                        ['OnReport', 'string', 'no-op'],\r\n",
					"                                        ['ParentalSalutation', 'string', 'no-op'],\r\n",
					"                                        ['PartTime', 'string', 'no-op'],\r\n",
					"                                        ['PostCode', 'string', 'no-op'],\r\n",
					"                                        ['PreviousLegalSurname', 'string', 'no-op'],\r\n",
					"                                        ['PupilPremium', 'string', 'no-op'],\r\n",
					"                                        ['QuickNote', 'string', 'no-op'],\r\n",
					"                                        ['ReasonForLeaving', 'string', 'no-op'],\r\n",
					"                                        ['RegGroup', 'string', 'no-op'],\r\n",
					"                                        ['RegGroupId', 'string', 'no-op'],\r\n",
					"                                        ['Religion', 'string', 'no-op'],\r\n",
					"                                        ['ReligionCode', 'string', 'no-op'],\r\n",
					"                                        ['RowHash', 'string', 'no-op'],\r\n",
					"                                        ['SENProvision', 'string', 'no-op'],\r\n",
					"                                        ['ServiceChild', 'string', 'no-op'],\r\n",
					"                                        ['ServiceChildSource', 'string', 'no-op'],\r\n",
					"                                        ['StandardYearGroupCode', 'string', 'no-op'],\r\n",
					"                                        ['StandardYearGroupName', 'string', 'no-op'],\r\n",
					"                                        ['Street', 'string', 'no-op'],\r\n",
					"                                        ['StudentStatus', 'string', 'no-op'],\r\n",
					"                                        ['Surname', 'string', 'no-op'],\r\n",
					"                                        ['TownOrCity', 'string', 'no-op'],\r\n",
					"                                        ['TravellerSource', 'string', 'no-op'],\r\n",
					"                                        ['UPN', 'string', 'no-op'],\r\n",
					"                                        ['UniformAllowance', 'string', 'no-op'],\r\n",
					"                                        ['UniqueLearnerNumber', 'string', 'no-op'],\r\n",
					"                                        ['WorkEmail', 'string', 'no-op'],\r\n",
					"                                        ['XID', 'string', 'no-op'],\r\n",
					"                                        ['YSSA', 'string', 'no-op'],\r\n",
					"                                        ['YearGroup', 'string', 'no-op'],\r\n",
					"                                        ['YearGroupId', 'string', 'no-op'],\r\n",
					"                                        ['YearTaughtIn', 'string', 'no-op'],\r\n",
					"                                        ['formerUPN', 'string', 'no-op'],\r\n",
					"                                        ['SchoolID', 'string', 'no-op'],\r\n",
					"                                        ['AddressBlock', 'string', 'no-op'],\r\n",
					"                                        ['UniqueStudentId', 'string', 'hash']\r\n",
					"                                        ] \r\n",
					"\r\n",
					"\r\n",
					"        self.schemas['attendancesummary'] = [['Id', 'string', 'no-op'],\r\n",
					"                                            ['XID', 'string', 'no-op'],\r\n",
					"                                            ['MIS_ID', 'string', 'no-op'],\r\n",
					"                                            ['IdaasId', 'string', 'no-op'],\r\n",
					"                                            ['AttStatsStartDate', 'string', 'no-op'],\r\n",
					"                                            ['AttStatsEndDate', 'string', 'no-op'],\r\n",
					"                                            ['NumPossMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumPresMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumAEAMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumAuthAbsMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumUnauthAbsMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumMissMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumLateMarks', 'string', 'no-op'],\r\n",
					"                                            ['NumLateBeforeRegMarks', 'string', 'no-op'],\r\n",
					"                                            ['Marks', 'string', 'mask'],\r\n",
					"                                            ['UniqueAttendanceId', 'string', 'hash'],\r\n",
					"                                            ['SchoolID', 'string', 'no-op']] \r\n",
					"\r\n",
					"        self.schemas['groups'] = [['Code', 'string', 'no-op'],\r\n",
					"                                ['ExternalId', 'string', 'no-op'],\r\n",
					"                                ['Id', 'string', 'no-op'],\r\n",
					"                                ['IdaasId', 'string', 'no-op'],\r\n",
					"                                ['LastUpdated', 'string', 'no-op'],\r\n",
					"                                ['Name', 'string', 'no-op'],\r\n",
					"                                ['NumStudents', 'string', 'no-op'],\r\n",
					"                                ['PlatformId', 'string', 'no-op'],\r\n",
					"                                ['PrimaryStaffId', 'string', 'no-op'],\r\n",
					"                                ['RowHash', 'string', 'mask'],\r\n",
					"                                ['Staff', 'string', 'no-op'],\r\n",
					"                                ['Type', 'string', 'no-op'],\r\n",
					"                                ['XID', 'string', 'no-op'],\r\n",
					"                                ['SchoolID', 'string', 'no-op'],\r\n",
					"                                ['UniqueGroupId', 'string', 'hash']] \r\n",
					"\r\n",
					"        self.schemas['HistoricalAttendanceSummary'] = [['EndDate', 'string', 'no-op'],\r\n",
					"                                                ['Id','string', 'no-op'],\r\n",
					"                                                ['SchoolYear', 'string', 'no-op'],\r\n",
					"                                                ['StartDate', 'string', 'no-op'],\r\n",
					"                                                ['StudentId', 'string', 'no-op'],\r\n",
					"                                                ['SchoolID', 'string', 'no-op'],\r\n",
					"                                                ['UniqueHistoricalAttendanceId', 'string', 'hash'],\r\n",
					"                                                ['Marks', 'string', 'no-op']]\r\n",
					"\r\n",
					"        self.schemas['staff'] = [[\"Apartment\",\"string\", 'no-op'],\r\n",
					"                                [\"Country\",\"string\", 'no-op'],\r\n",
					"                                [\"County\",\"string\", 'no-op'],\r\n",
					"                                [\"DateOfBirth\", \"string\", 'no-op'],\r\n",
					"                                [\"DisplayName\", 'string', 'no-op'],\r\n",
					"                                [\"District\",\"string\", 'no-op'],\r\n",
					"                                [\"EmploymentEnd\",\"string\", 'no-op'],\r\n",
					"                                [\"EmploymentStart\", 'string', 'no-op'],\r\n",
					"                                [\"ExternalId\",\"string\", 'no-op'],\r\n",
					"                                [\"Forename\",\"string\", 'no-op'],\r\n",
					"                                [\"Gender\",\"string\", 'no-op'],\r\n",
					"                                [\"HomeEmail\", 'string', 'no-op'],\r\n",
					"                                [\"HomePhone\", 'string', 'no-op'],\r\n",
					"                                [\"HouseName\", 'string', 'no-op'],\r\n",
					"                                [\"HouseNo\", 'string', 'no-op'],\r\n",
					"                                [\"Id\", 'string', 'no-op'],\r\n",
					"                                [\"IdaasEmail\", \"string\", 'no-op'],\r\n",
					"                                [\"IdaasId\", \"string\", 'no-op'],\r\n",
					"                                [\"IsSupply\", \"string\", 'no-op'],\r\n",
					"                                [\"IsSupport\", 'string', 'no-op'],\r\n",
					"                                [\"IsTeacher\", \"string\", 'no-op'],\r\n",
					"                                [\"LastUpdated\", \"string\", 'no-op'],\r\n",
					"                                [\"LegalForename\", \"string\", 'no-op'],\r\n",
					"                                [\"LegalSurname\", 'string', 'no-op'],\r\n",
					"                                [\"MiddleName\", \"string\", 'no-op'],\r\n",
					"                                [\"MobilePhone\", \"string\", 'no-op'],\r\n",
					"                                [\"NINumber\", \"string\", 'no-op'],\r\n",
					"                                [\"PayrollNumber\", \"string\", 'no-op'],\r\n",
					"                                [\"PostCode\", 'string', 'no-op'],\r\n",
					"                                [\"RegGroup\", \"string\", 'no-op'],\r\n",
					"                                [\"RoleCodes\", \"string\", 'no-op'],\r\n",
					"                                [\"Roles\", 'string', 'no-op'],\r\n",
					"                                [\"RowHash\", 'string', 'mask'],\r\n",
					"                                [\"StaffCode\", \"string\", 'no-op'],\r\n",
					"                                [\"StaffStatus\", 'string', 'no-op'],\r\n",
					"                                [\"Street\", \"string\", 'no-op'],\r\n",
					"                                [\"Suffix\", 'string', 'no-op'],\r\n",
					"                                [\"Surname\", \"string\", 'no-op'],\r\n",
					"                                [\"TeacherCategory\", \"string\", 'no-op'],\r\n",
					"                                [\"TeacherNumber\", 'string', 'no-op'],\r\n",
					"                                [\"Title\", 'string', 'no-op'],\r\n",
					"                                [\"TownOrCity\", 'string', 'no-op'],\r\n",
					"                                [\"WorkEmail\", 'string', 'no-op'],\r\n",
					"                                [\"WorkPhone\", \"string\", 'no-op'],\r\n",
					"                                [\"XID\", \"string\", 'no-op'],\r\n",
					"                                ['SchoolID', 'string', 'no-op'],\r\n",
					"                                ['UniqueStaffId','string','hash'],\r\n",
					"                                [\"AddressBlock\",'string', 'no-op']]\r\n",
					"\r\n",
					"\r\n",
					"        self.schemas['StudentMembers'] = [['EndDate', 'string', 'no-op'],\r\n",
					"                                        ['GroupExternalId', 'string', 'no-op'],\r\n",
					"                                        ['GroupId', 'string', 'no-op'],\r\n",
					"                                        ['GroupIdaasId', 'string', 'no-op'],\r\n",
					"                                        ['Id', 'string', 'no-op'],\r\n",
					"                                        ['LastUpdated', 'string', 'no-op'],\r\n",
					"                                        ['RowHash', 'string', 'mask'],\r\n",
					"                                        ['StartDate', 'string', 'no-op'],\r\n",
					"                                        ['StudentExternalId', 'string', 'no-op'],\r\n",
					"                                        ['StudentId', 'string', 'no-op'],\r\n",
					"                                        ['StudentIdaasId', 'string', 'no-op'],\r\n",
					"                                        ['SchoolID', 'string', 'no-op'],\r\n",
					"                                        ['UniqueStudentId', 'string', 'no-op'],\r\n",
					"                                        ['UniqueGroupId', 'string', 'no-op'],\r\n",
					"                                        ['UniqueStudentMemberId', 'string', 'hash']]\r\n",
					" \r\n",
					"    def set_oea_workspace(self, workspace_name):\r\n",
					"        oea.set_workspace(workspace_name)\r\n",
					"    \r\n",
					"    def json_from_xporter(self, source_path, multiline):\r\n",
					"        print(source_path)\r\n",
					"        options = {'format':'json', 'multiline':multiline}\r\n",
					"        df = spark.read.load(source_path, **options)\r\n",
					"        return df\r\n",
					"   \r\n",
					"    def get_oea_path(self):\r\n",
					"        return 'abfss://oea@' + oea.storage_account + '.dfs.core.windows.net'\r\n",
					"\r\n",
					"    def land_to_stage3(self, data, entity_path, filename):\r\n",
					"        sink_path = f'stage3/Transactional/{entity_path}/{filename}'\r\n",
					"        oea.write(data, sink_path)\r\n",
					"        return sink_path\r\n",
					"\r\n",
					"    def overwrite_to_path(self, df, destination_path, save_format = \"parquet\", primary_key='id'):\r\n",
					"        destination_url = oea.to_url(destination_path)\r\n",
					"        df = df.dropDuplicates([primary_key])\r\n",
					"        df.write.format(save_format).mode('overwrite').save(destination_url)\r\n",
					"\r\n",
					"    def _prepare_schoolinfo(self):\r\n",
					"        from pyspark.sql.functions import lit\r\n",
					"        #oea.rm_if_exists(oea.stage1np + '/xporter/schoolinfocsv')\r\n",
					"        df_schoolinfo = None\r\n",
					"        # loop through school EstabId folders landed by Xporter and union schoolinfo\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            if folder.isnumeric():\r\n",
					"                print(folder)\r\n",
					"                try:\r\n",
					"                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/SchoolInfo*'\r\n",
					"                    print(xporterPath)\r\n",
					"                    df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    df.show()\r\n",
					"                    dfc = df.select(F.explode('SchoolInfo').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    dfc.show()\r\n",
					"                    dfc = dfc.drop('Address')\r\n",
					"                    newdf = dfc.withColumn(\"Address\",col(\"RowHash\"))\r\n",
					"                    newdf = newdf.withColumn('SchoolID',lit(folder))\r\n",
					"                    newdf = newdf.withColumn('SchoolKey',lit(folder))\r\n",
					"                    if df_schoolinfo is None:\r\n",
					"                        df_schoolinfo = newdf\r\n",
					"                    else:\r\n",
					"                        df_schoolinfo = df_schoolinfo.union(newdf)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"        \r\n",
					"        csvString = df_schoolinfo.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/SchoolInfo', 'SchoolInfo.csv', oea.DELTA_BATCH_DATA)\r\n",
					"\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/SchoolInfo')\r\n",
					"        display(df)        \r\n",
					"        \r\n",
					"    def ingest_schoolinfo(self):\r\n",
					"        oea.ingest(f'xporter/SchoolInfo', 'SchoolID')\r\n",
					"        oea.refine('xporter/SchoolInfo', self.schemas['schoolinfo'], 'SchoolID')\r\n",
					"\r\n",
					"\r\n",
					"    def ingest_schoolinfo_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.schoolinfo\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.schoolinfo_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/schoolinfo_ingested',save_format = \"parquet\", primary_key='SchoolID')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/schoolinfo_refined',save_format = \"parquet\", primary_key='SchoolID')\r\n",
					"        \r\n",
					"    \r\n",
					"    def _prepare_students(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        #oea.rm_if_exists(oea.stage1np + '/xporter/schoolinfocsv')\r\n",
					"        df_studinfo = None\r\n",
					"        # loop through school EstabId folders landed by Xporter and union schoolinfo\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            if folder.isnumeric():\r\n",
					"                print(folder)\r\n",
					"                try:\r\n",
					"                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/Students*'\r\n",
					"                    df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    dfc = df.select(F.explode('Students').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    dfc = dfc.drop('AddressBlock')\r\n",
					"                    dfc = dfc.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
					"                    dfc = dfc.withColumn('SchoolID',lit(folder))\r\n",
					"                    newdf = dfc.withColumn(\"UniqueStudentId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))\r\n",
					"                    newdf.show()\r\n",
					"                    if df_studinfo is None:\r\n",
					"                        df_studinfo = newdf\r\n",
					"                    else:\r\n",
					"                        df_studinfo = df_studinfo.union(newdf)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"        \r\n",
					"        print('df_studinfo')\r\n",
					"        df_studinfo.show()\r\n",
					"        df_studinfo = df_studinfo.filter(col(\"UPN\") != \"undefined\")\r\n",
					"        df_studinfo = df_studinfo.filter(~isnull(col(\"UPN\")))\r\n",
					"        df_studinfo = df_studinfo.filter((length(trim(col(\"UPN\"))) > 9))\r\n",
					"        csvString = df_studinfo.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/Students', 'Students.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/Students')\r\n",
					"        display(df)\r\n",
					"    \r\n",
					"\r\n",
					"    def ingest_students(self):\r\n",
					"        oea.ingest(f'xporter/Students', 'UniqueStudentId')\r\n",
					"        oea.refine('xporter/Students', self.schemas['students'], 'UniqueStudentId')\r\n",
					"    \r\n",
					"    \r\n",
					"    def ingest_students_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.students\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.students_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/students_ingested',save_format = \"parquet\", primary_key='UniqueStudentId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/students_refined',save_format = \"parquet\", primary_key='UniqueStudentId')\r\n",
					"\r\n",
					"\r\n",
					"    def _prepare_attendancesummary(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        df_attendancesummary = None\r\n",
					"        for folder in oea.get_folders(xporter.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            if folder.isnumeric():\r\n",
					"                print(folder)\r\n",
					"                try:\r\n",
					"                    xporterPath = xporter.get_oea_path()+'/Transactional/xporter/'+folder+'/AttendanceSummary*'\r\n",
					"                    new_df = xporter.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    new_df = new_df.select(F.explode('AttendanceSummary').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    new_df = new_df.drop('AddressBlock')\r\n",
					"                    new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
					"                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
					"                    new_df = new_df.withColumn(\"UniqueAttendanceId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
					"                    if df_attendancesummary is None:\r\n",
					"                        df_attendancesummary = new_df\r\n",
					"                    else:\r\n",
					"                        df_attendancesummary = df_attendancesummary.union(new_df)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"\r\n",
					"        print(df_attendancesummary)\r\n",
					"        df_attendancesummary.show()   \r\n",
					"        csvString = df_attendancesummary.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/AttendanceSummary', 'attendancesummary.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/AttendanceSummary')\r\n",
					"        display(df)\r\n",
					"\r\n",
					"    def ingest_attendancesummary(self):\r\n",
					"        oea.ingest(f'xporter/AttendanceSummary', 'UniqueAttendanceId')\r\n",
					"        oea.refine('xporter/AttendanceSummary', self.schemas['attendancesummary'], 'UniqueAttendanceId')\r\n",
					"    \r\n",
					"    def ingest_attendancesummary_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.attendancesummary\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.attendancesummary_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/attendancesummary_ingested',save_format = \"parquet\", primary_key='UniqueAttendanceId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/attendancesummary_refined',save_format = \"parquet\", primary_key='UniqueAttendanceId')\r\n",
					"\r\n",
					"    \r\n",
					"    def _prepare_groups(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        df_groups1 = None\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            print(folder)\r\n",
					"            if folder.isnumeric():\r\n",
					"                try:\r\n",
					"                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/groups*'\r\n",
					"                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    new_df = new_df.select(F.explode('Group').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
					"                    new_df = new_df.withColumn(\"UniqueGroupId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
					"                    if df_groups1 is None:\r\n",
					"                        df_groups1 = new_df\r\n",
					"                    else:\r\n",
					"                        df_groups1 = df_groups1.union(new_df)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"\r\n",
					"        csvString = df_groups1.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/Groups', 'Groups.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/Groups')\r\n",
					"        display(df)\r\n",
					"        \r\n",
					"\r\n",
					"\r\n",
					"    def ingest_groups(self):\r\n",
					"        oea.ingest(f'xporter/Groups', 'UniqueGroupId')\r\n",
					"        oea.refine('xporter/Groups', self.schemas['groups'], 'UniqueGroupId')\r\n",
					"    \r\n",
					"    def ingest_groups_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.groups\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.groups_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/groups_ingested',save_format = \"parquet\", primary_key='UniqueGroupId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/groups_refined',save_format = \"parquet\", primary_key='UniqueGroupId')\r\n",
					"\r\n",
					"    \r\n",
					"    def _prepare_HistoricalAttendanceSummary(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        df_histattendancSummary = None\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            if folder.isnumeric():\r\n",
					"                print(folder)\r\n",
					"            try:\r\n",
					"                xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/HistoricalAttendanceSummary*'\r\n",
					"                new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                new_df = new_df.select(F.explode('HistoricalAttendanceSummary').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                new_df = new_df.drop('AddressBlock')\r\n",
					"                new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
					"                new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
					"                new_df = new_df.withColumn(\"UniqueHistoricalAttendanceId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"Id\")))           \r\n",
					"                if df_histattendancSummary is None:\r\n",
					"                    df_histattendancSummary = new_df\r\n",
					"                else:\r\n",
					"                    df_histattendancSummary = df_histattendancSummary.union(new_df)\r\n",
					"            except:\r\n",
					"                pass\r\n",
					"\r\n",
					"        csvString = df_histattendancSummary.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/HistoricalAttendanceSummary', 'HistoricalAttendanceSummary.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/Students')\r\n",
					"        display(df)\r\n",
					"\r\n",
					"\r\n",
					"\r\n",
					"    def ingest_HistoricalAttendanceSummary(self):\r\n",
					"        oea.ingest(f'xporter/HistoricalAttendanceSummary', 'UniqueHistoricalAttendanceId')\r\n",
					"        oea.refine('xporter/HistoricalAttendanceSummary', self.schemas['HistoricalAttendanceSummary'], 'UniqueHistoricalAttendanceId')#ingesting into stage 2\"\"\"#ingesting into stage 2\"\"\"\r\n",
					"    \r\n",
					"    \r\n",
					"    def ingest_HistoricalAttendanceSummary_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.historicalattendancesummary\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.historicalattendancesummary_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/historicalattendancesummary_ingested',save_format = \"parquet\", primary_key='UniqueHistoricalAttendanceId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/historicalattendancesummary_refined',save_format = \"parquet\", primary_key='UniqueHistoricalAttendanceId')\r\n",
					"   \r\n",
					"\r\n",
					"    def _prepare_staff(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        df_staff = None\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            print(folder)\r\n",
					"            if folder.isnumeric():\r\n",
					"                try:\r\n",
					"                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/staff*'\r\n",
					"                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    new_df = new_df.select(F.explode('staff').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
					"                    new_df = new_df.drop('AddressBlock')\r\n",
					"                    new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
					"                    new_df = new_df.withColumn(\"UniqueStaffId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
					"                    if df_staff is None:\r\n",
					"                        df_staff = new_df\r\n",
					"                    else:\r\n",
					"                        df_staff = df_staff.union(new_df)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"\r\n",
					"        csvString = df_staff.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/Staff', 'Staff.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/Staff')\r\n",
					"        display(df)\r\n",
					"\r\n",
					"    \r\n",
					"    def ingest_staff(self):\r\n",
					"        oea.ingest(f'xporter/Staff', 'UniqueStaffId')\r\n",
					"        oea.refine('xporter/Staff', self.schemas['staff'], 'UniqueStaffId')\r\n",
					"    \r\n",
					"    \r\n",
					"    def ingest_staff_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.staff\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.staff_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/staff_ingested',save_format = \"parquet\", primary_key='UniqueStaffId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/staff_refined',save_format = \"parquet\", primary_key='UniqueStaffId')\r\n",
					"    \r\n",
					"    def _prepare_StudentMembers(self):\r\n",
					"        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
					"        df_studentmembers = None\r\n",
					"        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
					"            print(folder)\r\n",
					"            if folder.isnumeric():\r\n",
					"                try:\r\n",
					"                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/groups*'\r\n",
					"                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
					"                    new_df = new_df.select(F.explode('StudentMembers').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
					"                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
					"                    new_df = new_df.withColumn(\"UniqueStudentId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"StudentIdaasId\")))\r\n",
					"                    new_df = new_df.withColumn(\"UniqueGroupId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"GroupIdaasId\")))\r\n",
					"                    new_df = new_df.withColumn(\"UniqueStudentMemberId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"Id\")))           \r\n",
					"                    if df_studentmembers is None:\r\n",
					"                        df_studentmembers = new_df\r\n",
					"                    else:\r\n",
					"                        df_studentmembers = df_studentmembers.union(new_df)\r\n",
					"                except:\r\n",
					"                    pass\r\n",
					"\r\n",
					"        csvString = df_studentmembers.toPandas().to_csv(index=False)\r\n",
					"        oea.land(csvString, 'xporter/StudentMembers', 'StudentMembers.csv', oea.DELTA_BATCH_DATA)\r\n",
					"        df = oea.load_csv(f'stage1/Transactional/xporter/StudentMembers')\r\n",
					"        display(df)\r\n",
					"\r\n",
					"    \r\n",
					"    def ingest_StudentMembers(self):\r\n",
					"        oea.ingest(f'xporter/StudentMembers', 'UniqueStudentMemberId')\r\n",
					"        oea.refine('xporter/StudentMembers', self.schemas['StudentMembers'], 'UniqueStudentMemberId')\r\n",
					"\r\n",
					"    \r\n",
					"    def ingest_StudentMembers_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
					"        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
					"        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.studentmembers\")\r\n",
					"        display(df_ingested)\r\n",
					"        df_ingested.printSchema()\r\n",
					"        df_refined = spark.sql(f\"select * from {refineDatabaseName}.studentmembers_lookup\")\r\n",
					"        display(df_refined)\r\n",
					"        #writing files in parquet format\r\n",
					"        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/studentmembers_ingested',save_format = \"parquet\", primary_key='UniqueStudentMemberId')\r\n",
					"        xporter.overwrite_to_path(df_refined,f'stage3/xporter/studentmembers_refined',save_format = \"parquet\", primary_key='UniqueStudentMemberId')\r\n",
					"        \r\n",
					"xporter = Xporter()"
				]
			}
		]
	}
}